{
  "args": {
    "model_path": "/scratch/gpfs/OLGARUS/jw4199/model_weights_path/Ouro-2.6B-Thinking",
    "total_ut_steps": 4,
    "teacher_loops": 4,
    "student_loops": 2,
    "loop_mapping": "shift",
    "weight_schedule": "uniform",
    "weight_gamma": 1.0,
    "divergence": "jsd",
    "teacher_context": "opsd",
    "teacher_mode": "same",
    "ema_decay": 0.99,
    "sft_checkpoint": null,
    "use_latest_sft": false,
    "no_sft_checkpoint": true,
    "sft_output_dir": "/scratch/gpfs/OLGARUS/jw4199/distillation/LLOPSD/sft_experiments/sft_ouro_math_output",
    "train_file": "/scratch/gpfs/OLGARUS/jw4199/datasets/MATH/math_train.jsonl",
    "num_generations": 1,
    "num_prompts_per_batch": 32,
    "temperature": 1.0,
    "learning_rate": 1e-06,
    "weight_decay": 0.1,
    "max_grad_norm": 0.1,
    "warmup_ratio": 0.1,
    "lr_scheduler_type": "constant",
    "gradient_accumulation_steps": 2,
    "forward_batch_size": 2,
    "ppo_max_token_len": 8192,
    "log_prob_max_token_len": 8192,
    "no_gradient_checkpointing": false,
    "max_prompt_length": 1024,
    "max_completion_length": 2048,
    "num_train_epochs": 1,
    "max_steps": 3,
    "lora_r": 32,
    "lora_alpha": 64,
    "no_lora": true,
    "lora_target_modules": "attention",
    "eval_steps": 5,
    "val_batch_size": 64,
    "val_max_new_tokens": 3072,
    "math500_test_file": "/scratch/gpfs/OLGARUS/jw4199/datasets/MATH-500/MATH-500.test.jsonl",
    "no_validation": true,
    "skip_initial_validation": true,
    "logging_steps": 1,
    "save_steps": 1,
    "wandb_project": "LLOPSD",
    "no_wandb": false,
    "use_vllm": true,
    "no_vllm": false,
    "vllm_gpu_memory_utilization": 0.45,
    "vllm_tensor_parallel_size": 1,
    "vllm_enforce_eager": false,
    "ref_offload": false,
    "n_gpus": 4,
    "nnodes": 1,
    "output_dir": "./llopsd_output/4753147",
    "seed": 42,
    "dataloader_num_workers": 4,
    "debug": false
  },
  "verl_config": {
    "algorithm": {
      "adv_estimator": "grpo",
      "use_kl_in_reward": false,
      "kl_coef": 0.0,
      "gamma": 1.0,
      "lam": 1.0
    },
    "data": {
      "train_batch_size": 32,
      "val_batch_size": 32,
      "max_prompt_length": 1024,
      "max_response_length": 2048,
      "filter_overlong_prompts": true,
      "truncation": "error",
      "sampler": null,
      "shuffle": true,
      "dataloader_num_workers": 4
    },
    "actor_rollout_ref": {
      "model": {
        "path": "/scratch/gpfs/OLGARUS/jw4199/model_weights_path/Ouro-2.6B-Thinking",
        "use_remove_padding": true,
        "enable_gradient_checkpointing": true,
        "trust_remote_code": true,
        "lora_rank": 0,
        "lora_alpha": 0,
        "target_modules": "q_proj,k_proj,v_proj,o_proj",
        "exclude_modules": null
      },
      "actor": {
        "_target_": "verl.workers.config.FSDPActorConfig",
        "strategy": "fsdp",
        "ppo_epochs": 1,
        "entropy_coeff": 0.0,
        "use_kl_loss": false,
        "kl_loss_coef": 0.0,
        "kl_loss_type": "low_var_kl",
        "ppo_mini_batch_size": 32,
        "ppo_micro_batch_size": null,
        "ppo_micro_batch_size_per_gpu": 2,
        "use_dynamic_bsz": true,
        "ppo_max_token_len_per_gpu": 8192,
        "ulysses_sequence_parallel_size": 1,
        "entropy_from_logits_with_chunking": false,
        "entropy_checkpointing": false,
        "loss_agg_mode": "token-mean",
        "grad_clip": 0.1,
        "optim": {
          "_target_": "verl.workers.config.FSDPOptimizerConfig",
          "optimizer": "AdamW8bit",
          "optimizer_impl": "bitsandbytes.optim",
          "lr": 1e-06,
          "weight_decay": 0.1,
          "betas": [
            0.9,
            0.999
          ],
          "override_optimizer_config": null
        },
        "fsdp_config": {
          "_target_": "verl.workers.config.FSDPEngineConfig",
          "param_offload": false,
          "optimizer_offload": false,
          "fsdp_size": -1,
          "dtype": "bfloat16"
        },
        "checkpoint": {
          "_target_": "verl.trainer.config.CheckpointConfig",
          "save_contents": [
            "model",
            "optimizer",
            "extra"
          ],
          "load_contents": [
            "model",
            "optimizer",
            "extra"
          ],
          "async_save": false
        }
      },
      "rollout": {
        "_target_": "verl.workers.config.rollout.RolloutConfig",
        "name": "vllm",
        "mode": "sync",
        "n": 1,
        "tensor_model_parallel_size": 1,
        "data_parallel_size": 1,
        "pipeline_model_parallel_size": 1,
        "load_format": "auto",
        "gpu_memory_utilization": 0.45,
        "enforce_eager": false,
        "free_cache_engine": false,
        "enable_prefix_caching": true,
        "log_prob_micro_batch_size": null,
        "log_prob_micro_batch_size_per_gpu": null,
        "log_prob_max_token_len_per_gpu": 8192,
        "log_prob_use_dynamic_bsz": true,
        "temperature": 1.0,
        "max_model_len": 3072,
        "enable_chunked_prefill": true,
        "prompt_length": 1024,
        "response_length": 2048,
        "multi_turn": {
          "enable": false
        }
      },
      "ref": {
        "log_prob_micro_batch_size": null,
        "log_prob_micro_batch_size_per_gpu": null,
        "log_prob_max_token_len_per_gpu": 8192,
        "log_prob_use_dynamic_bsz": true,
        "fsdp_config": {
          "_target_": "verl.workers.config.FSDPEngineConfig",
          "param_offload": false
        }
      },
      "hybrid_engine": true,
      "teacher_loops": 4,
      "student_loops": 2,
      "loop_mapping_strategy": "shift",
      "weight_schedule": "uniform",
      "weight_gamma": 1.0,
      "divergence": "jsd",
      "teacher_context": "opsd",
      "teacher_mode": "same",
      "ema_decay": 0.99,
      "total_ut_steps": 4
    },
    "critic": {
      "enable": false
    },
    "trainer": {
      "experiment_name": "LLOPSD-Ouro-2.6B-Thinking-T4S2-shift",
      "project_name": "LLOPSD",
      "logger": [
        "wandb"
      ],
      "n_gpus_per_node": 4,
      "nnodes": 1,
      "total_epochs": 1,
      "save_freq": 1,
      "test_freq": -1,
      "val_before_train": false,
      "critic_warmup": 0,
      "validation_data_dir": "./llopsd_output/4753147/validation_outputs",
      "device": "cuda",
      "total_training_steps": null,
      "resume_mode": "disable",
      "esi_redundant_time": 0,
      "balance_batch": false,
      "default_local_dir": "./llopsd_output/4753147",
      "default_hdfs_dir": null,
      "gradient_accumulation_steps": 2
    },
    "custom_reward_function": {
      "path": "/scratch/gpfs/OLGARUS/jw4199/distillation/LLOPSD/math_utils/reward.py",
      "name": "compute_score"
    },
    "global_profiler": {
      "steps": null,
      "profile_continuous_steps": null
    },
    "reward_model": {
      "enable": false,
      "launch_reward_fn_async": false
    }
  }
}